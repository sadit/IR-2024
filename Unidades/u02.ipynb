{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b606b63e-967d-4d4d-85e4-e02a32020425",
   "metadata": {},
   "source": [
    "# BÃºsqueda de texto completo\n",
    "Autor: Eric S. Tellez <eric.tellez@infotec.mx> <br/>\n",
    "\n",
    "Tal vez la tarea mÃ¡s emblemÃ¡tica de la RecuperaciÃ³n de InformaciÃ³n es la bÃºsqueda de _texto completo_.\n",
    "El problema consiste en dado un corpus grande de documentos, preprocesarlo para crear una estructura de bÃºsqueda que permita resolver consultas de manera eficiente. Una consulta es un texto corto que especÃ­fica lo que se desea encontrar en la colecciÃ³n. En particular, es un ejemplo de lo que se desea. Esto lleva a que la estructura de bÃºsqueda resuelve bÃºsquedas por similitud.\n",
    "\n",
    "La similitud, es entonces un tema central, pero para medirla lo primero es tener una representaciÃ³n de los datos que capture las propiedades deseadas (que serÃ¡n despuÃ©s evaluadas para medir la similitud). La manera mÃ¡s tradicional de hacerlo, es el uso de un modelo basado en bolsa de palabras (BOW). En dicho modelo, el texto es preprocesado, toquenizado y vectorizado.\n",
    "\n",
    "- El preprocesamiento incluye tratamientos tan simples como eliminar sÃ­mbolos no deseados, eliminaciÃ³n de variantes lÃ©xicas, reducciÃ³n a raÃ­ces o lemas, correcciÃ³n de ortografÃ­a, eliminiaciÃ³n de palabras comunes (stop words). \n",
    "- El toquenizado es el proceso donde el texto es partido, en frases u oraciones, y finalmente en palabras y sÃ­mbolos que son unidades completas. En este punto tambiÃ©n es posible realizar normalizaciones, asÃ­ como tambiÃ©n realizar limpieza basada en estadÃ­sticas de los tÃ©rminos.\n",
    "- El vectorizado utiliza el vocabulario de una colecciÃ³n $\\{t_i\\}$ para generar una matriz de la colecciÃ³n, i.e., un vector por documento.\n",
    "\n",
    "Al proceso de modelar una colecciÃ³n mediante un vocabulario y luego ser capaces de generar una representaciÃ³n manejable por una computadora se le llama _modelo de lenguaje_.\n",
    "\n",
    "## Problema de bÃºsqueda\n",
    "Una vez que se tiene el modelo de lenguaje y que fue usado para vectorizar una colecciÃ³n $X$, la idea es ser capaces de resolver consultas $q \\in Q$, i.e., encontrar un subconjunto de $X$ de tamaÃ±o $k$ que mÃ¡s se _parezca_ a $q$. Las consultas deben ser codificadas al mismo espacio que los documentos, i.e., espacio vectorial. Entonces el problema se transforma en encontrar los elementos mÃ¡s parecidos, que dada la representaciÃ³n, es conveniente usar el coseno entre vectores:\n",
    "\n",
    "$$ \\cos(u, q) = \\frac{ \\sum_i {u_i \\cdot q_i}}{\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}} $$\n",
    "\n",
    "AsÃ­ mismo, $d(u, q) = \\arccos(\\cos(u, q))$ serÃ­a el Ã¡ngulo entre ambos vectores, que ademÃ¡s es una mÃ©trica. El problema entonces se transforma en encontrar los vecinos mÃ¡s cercanos en la colecciÃ³n, esto es, si deseamos $k$ resultados de una consulta, estarÃ­amos deseando encontrar aquel subconjunto $knn$ de la colecciÃ³n tal que $\\sum_{v \\in knn} d(v, q)$ sea mÃ­nimo comparado con todo subconjunto de tamaÃ±o $k$ de la colecciÃ³n de documentos.\n",
    "\n",
    "## Velocidad de consultas\n",
    "Para mejorar la soluciÃ³n de consultas, es posible crear una estructura de datos que simplifique el proceso de encontrar el subconjunto $knn$. En este problema, con una representaciÃ³n basada en bolsa de palabras, la estructura mÃ¡s adecuada es el _Ã­ndice invertido_.\n",
    "\n",
    "\n",
    "# Ãndice invertido\n",
    "\n",
    "Un Ã­ndice invertido es una representaciÃ³n dispersa de la matriz $W_{m,n}$ formada por $m$ componentes y $n$ documentos, i.e., cada celda $w_{t,i}$ es el peso asignado para el tÃ©rmino $t$ que ocurre en el documento $i$. Por construcciÃ³n, esta matriz tiene una gran cantidad de ceros, por lo que $W$ es altamente dispersa (pocos tÃ©rminos ocurren en un documento).\n",
    "\n",
    "$$ W \\left\\{\n",
    "\\begin{array}{rrrr r}\n",
    "                & \\vec x_1& \\vec x_2&       & \\vec x_n \\\\\n",
    "t_1 \\rightarrow & w_{1,1} & w_{1,2} & \\dots & w_{1,n} \\\\\n",
    "t_2 \\rightarrow & w_{2,1} & w_{2,2} &       & w_{2,n} \\\\\n",
    "                & \\vdots  &         & \\ddots&         \\\\\n",
    "t_m \\rightarrow & w_{m,1} & w_{m,2} &       & w_{m,n} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "La representaciÃ³n es entonces por fila, a manera de lista de adjacencia; esto es, cada fila $t$ es representada por las tuplas $(i, w_{t,i})$, esto es, un Ã­ndice invertido es la siguiente estructura $W^*$\n",
    "\n",
    "$$ W^* \\left\\{\n",
    "\\begin{array}{rrr}\n",
    "t_1 & \\rightarrow & \\{(i, w_{1, i})\\} \\\\\n",
    "t_2 & \\rightarrow & \\{(i, w_{2, i})\\} \\\\\n",
    "\\vdots & \\vdots   &  \\hfill \\vdots \\hfill \\\\\n",
    "t_m & \\rightarrow & \\{(i, w_{m, i})\\} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "la tupla es usada siempre y cuando $w > 0$. Las tuplas suelen ordenarse por su identificador de columna, pero tambiÃ©n puede usarse el peso segÃºn convenga. A las filas suele llamarseles _listas de posteo_ (_posting lists_). Los requerimientos de una matriz densa son altÃ­simos ya que las representaciones de texto suelen ser de muy alta dimensiÃ³n. Si la representaciÃ³n contiene muchos ceros, como es el caso de una representaciÃ³n basada en un modelo lÃ©xico, es posible representar las matrices de manera dispersa y reducir enormemente los requisitos de la memorÃ­a. Como se verÃ¡ a continuaciÃ³n la representaciÃ³n tambiÃ©n influye enormemente en los tiempos de procesamiento.\n",
    "\n",
    "### BÃºsqueda mediante un Ã­ndice invertido\n",
    "\n",
    "La soluciÃ³n na\\\"ive de una obtener los $k$ documentos mÃ¡s similares es evaluar todos los vectores $\\vec{x}_i$, i.e., columnas de $W$, y determinar aquellos mÃ¡s similares, i.e., minimizar $d(\\vec{x}_i, q)$.\n",
    "\n",
    "El Ã­ndice invertido $W^*$ contiene la informaciÃ³n necesaria para realizar esta operaciÃ³n de manera eficiente. Primeramente, es necesario analizar la expresiÃ³n de $\\cos$. El denominador $\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}$, en sus partes es estÃ¡tico para cada vector, por lo que se puede preprocesar y no calcular de manera explÃ­cita para cada evaluaciÃ³n de $\\cos$. Con respecto al numerador corresponde al producto punto entre $\\vec{u}$ y $\\vec{q}$, $\\sum_i u_i \\cdot q_i$. Dicho esto, solo es necesario calcular los productos diferentes de cero; asÃ­ pues, la evaluaciÃ³n eficiente de $\\cos$ corresponde con una evaluaciÃ³n eficiente de la intersecciÃ³n de las componentes diferentes de cero. Los algoritmos como SvS, BY o BK, pueden ser de gran ayuda para este cÃ¡lculo. Note que aunque que los pesos con valor cero no se representan en $W^*$, dicho Ã­ndice representa informaciÃ³n por fila, lo cual no permite hacer operaciones eficientes entre $q$ y los vectores columna $\\vec x$ individuales.\n",
    "\n",
    "\n",
    "Afortunadamente, la evaluaciÃ³n se puede hacer eficiente para todo el conjunto de posibles candidatos (aquellos donde el producto punto contra $q$ sea diferente de cero). Para esto, se toman las componentes diferentes de cero en $q$, se toman las listas de adyacencia de $W^*$ y se procede a unirlas de manera eficiente. El conjunto de identificadores de documento resultado de esta uniÃ³n serÃ¡ aquel que debe ser evaluado para obtener el conjunto de documentos similares. \n",
    "Si uno toma la intersecciÃ³n, que puede ser mÃ¡s veloz de calcular, entonces podrÃ­an perderse documentos relevantes; es posible tambiÃ©n mandar el problema a un punto intermedio, es decir al problema de $t$-thresholds, donde se recupera un conjunto donde cada uno de los miembros aparece en al menos $t$ listas.\n",
    "La manera mÃ¡s eficiente, sin embargo, es realizar optimizaciones por filtrado de pesos o mejorando los esquemas de pesado; la idea general entonces es desaparecer entradas de $W*$ de tal forma que la uniÃ³n sea siempre pequeÃ±a. La adecuada optimizaciÃ³n de un Ã­ndice invertido puede hacerlo escalable a niveles realmente impresionantes.\n",
    "\n",
    "Los algoritmos de BK pueden ser utilizados para calcular la uniÃ³n y t-thresholds, asÃ­ como los algoritmos de mezcla clÃ¡sicos (_merge_). Es posible unir la operaciÃ³n de uniÃ³n con la operaciÃ³n de producto punto por vector usando los algoritmos adecuados.\n",
    "\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/invfilesearch.jl>\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/winvfilesearch.jl>\n",
    "- <https://github.com/sadit/Intersections.jl/blob/main/src/merge.jl>\n",
    "\n",
    "# Medidas de calidad (scores)\n",
    "La mediciÃ³n de la calidad en un sistema de bÃºsqueda es fundamental para obtener un sistema de RI adecuado. La idea bÃ¡sica es que un algoritmo recupere la informaciÃ³n adecuada para solventar los requerimientos de las consultas hechas por usuarios. Dicho de otra forma, si se piden $k$ documentos relacionados a una consulta $q$, se medirÃ¡ que porcentaje de esos $k$ son relevantes para el usuario.\n",
    "La evaluaciÃ³n de relevancia de un documento es hecha previamente por _usuarios expertos_ en el dominio del corpus y las consultas. A esta funciÃ³n de relevancia se le llama $\\textsf{recall}$.\n",
    "\n",
    "$$ \\textsf{recall}(\\text{doc. recuperados}, \\text{doc. esperados}) = \\frac{\\left| \\text{doc. recuperados} \\cap \\text{doc esperados} \\right|}{\\left|\\text{doc. esperados}\\right|} $$\n",
    "\n",
    "Note que no se espera precisamente que cada conjunto de resultados sea de tamaÃ±o idÃ©ntico, aunque esta serÃ¡ la norma en nuestro curso. Para obtener una estadÃ­stica fiable, la relevancia serÃ¡ promediada para obtener la calidad del modelo o algoritmo ante un conjunto de consultas. Llamaremos $\\textsf{macrorecall}$ al promedio de los recalls varias consultas.\n",
    "\n",
    "$$ \\textsf{macrorecall}(R, G) = \\frac{1}{|G|} \\sum_i \\textsf{recall}(R_i, G_i)$$\n",
    "\n",
    "El conjunto $R$ es el conjunto de resultados recuperados para un conjunto de consultas, mientras que $G$ es un conjunto especial de resultados que suele llamarse _gold standard_, que serÃ­a esa el conjunto de resultados fiables obtenidos a travÃ©s de la evaluaciÃ³n de expertos humanos.\n",
    "\n",
    "Es costoso y tardado construir un _gold standard_ para una tarea de recuperaciÃ³n de informaciÃ³n, y mÃ¡s aÃºn, para conjuntos de datos grandes. Es por eso que en este curso, evaluaremos la bondad de los modelos usados para la representaciÃ³n de los datos y las optimizaciones para bÃºsqueda mediante el uso de **tareas de clasificaciÃ³n**. En ese sentido la relaciÃ³n entre velocidad y calidad que se muestran no deberÃ¡n tomarse mÃ¡s que de manera informativa ya que no puede ligarse a un sistema de bÃºsqueda en grandes colecciones de documentos.\n",
    "\n",
    "## Midiendo la calidad usando clasificaciÃ³n\n",
    "En tÃ©rminos de clasificaciÃ³n se usarÃ¡ un modelo basado en vecinos cercanos ya que son naturalmente implementados con las mÃ¡quinas de bÃºsqueda. Pero se aconseja el uso de otros clasificadores en tareas de clasificaciÃ³n.\n",
    "\n",
    "A lo largo del resto del curso, siempre que sea fÃ¡cil se utilizarÃ¡n particiones separadas entre entramiento y prueba. Recuerde que no es nuestro objetivo la clasificaciÃ³n efectiva, y nuestro objetivo es medir la diferencia entre modelos de bÃºsqueda y medir la bondad o perdida de alguna caracterÃ­stica modificada a un modelo o algoritmo.\n",
    "\n",
    "### ClasificaciÃ³n de texto\n",
    "La clasificaciÃ³n de texto es una tarea de recuperaciÃ³n de informaciÃ³n que serÃ¡ solo tocada ligeramente en este curso, ya que esta fuera del alcance del mismo. Sin embargo, se usarÃ¡ en una de sus formas mÃ¡s sencillas para evaluaciÃ³n de la calidad de los modelos, como ya se menciono. El problema de clasificaciÃ³n consiste en aprender una funciÃ³n $\\phi(texto) \\rightarrow etiqueta$ apartir de un conjunto de un corpus etiquetado tal que para cada texto $t_i$ en el corpus, existe una $y_i$ que es la etiqueta de $t_i$, de tal forma que al usar un texto nunca antes visto $\\phi(texto')$ la funciÃ³n sea capaz de calcular una etiqueta. La funciÃ³n $\\phi$ basada en recuperar los $k$ vecinos cercanos ($knn$) sobre el corpus de entrenamiento y resolver con la etiqueta mÃ¡s popular entre los $knn$.\n",
    "\n",
    "Hay diferentes tipos de _scores_ que se utilizan, entre ellos el _accuracy_, _precision_, y _recall_, que es un sÃ­mil de nuestra funciÃ³n de recall. TambiÃ©n se suele tener en cuenta combinaciones de estos como _score_ $F_1$, que es la media armÃ³nica entre _precision_ y _recall_. Las funciones de _accuracy_, _precision_ y _recall_ se definen con respecto al nÃºmero de clases (diferentes etiquetas consideradas) y las funciones bÃ¡sicas TP (true positives), TN (true negatives), FP (false positives), FN (false negatives) <https://en.wikipedia.org/wiki/Precision_and_recall>. Dichas funciones son bien conocidas y usaremos las funciones implementadas en paquetes dedicados enfocando en nuestro objetivo de uso de la bÃºsqueda para medir la calidad de un modelo.\n",
    "\n",
    "\n",
    "## Modelos que toman en cuenta a los usuarios de manera personalizada\n",
    "Los requerimientos entre usuarios podrÃ­an asumirse diferentes, en ese caso, el problema cambiarÃ¡ su forma precisa ya que ahora se deberÃ¡ cumplir que el resultado de una consulta sea relevante para un usuario especÃ­fico, que deberÃ¡ ser modelado de alguna manera para poder generalizarlo. Esta consideraciÃ³n esta fuera del alcance de este curso.\n",
    "\n",
    "# Ejemplo\n",
    "\n",
    "El siguiente es un ejemplo de como cambia el desempeÃ±o usando una evaluaciÃ³n exhaustiva, un Ã­ndice invertido y una pequeÃ±a optimizaciÃ³n basada en modificaciÃ³n de pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb11ca12-b635-45bb-ac02-14523674ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Cursos/IR-2024/Unidades`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "using TextSearch, InvertedFiles, SimilaritySearch, KNearestCenters, TextSearch, StatsBase, LinearAlgebra, HypertextLiteral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae53fa62-8909-4249-9103-6a54232c183e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e9eb5-584e-4cda-8794-b2858c3804c7",
   "metadata": {},
   "source": [
    "### FunciÃ³n de clasificaciÃ³n para medir calidad de un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a515900-5a0a-4114-995f-9eb3157985d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scores (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"knn.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd994e-6be8-45c8-a0fc-8f05dfcf2636",
   "metadata": {},
   "source": [
    "## Funciones para leer y modelar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9482f05-8d88-4896-9b9e-646bc1da2abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_model_and_vectors (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function text_model_and_vectors(\n",
    "        corpus;\n",
    "        textconfig=TextConfig(group_usr=true, group_url=true, del_diac=true, lc=true, group_num=true, nlist=[1], qlist=[]),\n",
    "        voc=Vocabulary(textconfig, corpus),\n",
    "        model=VectorModel(IdfWeighting(), TfWeighting(), voc)\n",
    "    )\n",
    "    \n",
    "    vectors = vectorize_corpus(model, corpus)\n",
    "    (; textconfig, model, vectors)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1176ef00-1153-4cba-bb89-354d634c857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Cargando el corpus</h1>"
      ],
      "text/plain": [
       "<h1>Cargando el corpus</h1>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(unique(D.labels), T.model) = ([\"â™¡\", \"ğŸ˜’\", \"ğŸ’–\", \"ğŸ˜´\", \"ğŸ˜\", \"ğŸ˜“\", \"ğŸ˜¬\", \"ğŸ’™\", \"ğŸ˜ƒ\", \"ğŸ˜¡\", \"ğŸ¤“\", \"ğŸ™‚\", \"â¤\", \"ğŸ˜ \", \"ğŸ˜³\", \"ğŸ˜­\", \"ğŸ‘Œ\", \"ğŸŒš\", \"ğŸ˜…\", \"ğŸ˜\", \"ğŸ˜‹\", \"ğŸ˜•\", \"ğŸ˜‰\", \"ğŸ˜¢\", \"ğŸ˜±\", \"ğŸ’•\", \"ğŸ¤£\", \"ğŸ˜ª\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜»\", \"ğŸ¤­\", \"ğŸ’œ\", \"ğŸ™ˆ\", \"ğŸ™\", \"ğŸ˜¥\", \"ğŸ˜€\", \"ğŸ˜¤\", \"ğŸ˜©\", \"ğŸ˜˜\", \"ğŸ˜Š\", \"ğŸ™„\", \"ğŸ¤—\", \"ğŸ˜œ\", \"ğŸ˜‘\", \"âœ¨\", \"ğŸ˜°\", \"ğŸ˜‚\", \"ğŸ¶\", \"ğŸ™ƒ\", \"ğŸ™Š\", \"ğŸ¤¤\", \"ğŸ‘\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜£\", \"ğŸ˜Œ\", \"ğŸ¤”\", \"â™¥\", \"ğŸ’”\", \"ğŸ‘€\", \"ğŸ˜”\", \"ğŸ˜ˆ\", \"ğŸ˜«\"], {VectorModel\n",
      "    global_weighting: IdfWeighting()\n",
      "    local_weighting: TfWeighting()\n",
      "    vocsize: 41704\n",
      "    trainsize=45000\n",
      "    maxoccs=84742                                    \n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\"â™¡\", \"ğŸ˜’\", \"ğŸ’–\", \"ğŸ˜´\", \"ğŸ˜\", \"ğŸ˜“\", \"ğŸ˜¬\", \"ğŸ’™\", \"ğŸ˜ƒ\", \"ğŸ˜¡\"  â€¦  \"ğŸ˜\", \"ğŸ˜£\", \"ğŸ˜Œ\", \"ğŸ¤”\", \"â™¥\", \"ğŸ’”\", \"ğŸ‘€\", \"ğŸ˜”\", \"ğŸ˜ˆ\", \"ğŸ˜«\"], {VectorModel\n",
       "    global_weighting: IdfWeighting()\n",
       "    local_weighting: TfWeighting()\n",
       "    vocsize: 41704\n",
       "    trainsize=45000\n",
       "    maxoccs=84742                                    \n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(@htl \"<h1>Cargando el corpus</h1>\")\n",
    "\n",
    "include(\"read_datasets.jl\")\n",
    "D, Q = read_emojispace()\n",
    "T = text_model_and_vectors(D.text)\n",
    "\n",
    "@show unique(D.labels), T.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8671092-ee09-4370-b732-4d40d3d4b7b1",
   "metadata": {},
   "source": [
    "# Creando los diferentes mÃ©todos de bÃºsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7ccd91-c1c2-4a04-b792-d38a8c65342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{WeightedInvertedFile{Nothing, SimilaritySearch.AdjacencyLists.AdjacencyList{IdWeight}} vocsize=4954, n=45000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ã­ndice invertido\n",
    "invfile = WeightedInvertedFile(length(T.model.voc))\n",
    "append_items!(invfile, VectorDatabase(T.vectors))\n",
    "\n",
    "## indice invertido con filtros al vocabulario\n",
    "fmodel = filter_tokens(T.model) do t\n",
    "    7 <= t.ndocs <= 1000  # filtrando los tokens que ocurren en entre 7 y 1000 documentos\n",
    "end\n",
    "\n",
    "## usando el modelo reducido de tokens\n",
    "fT = text_model_and_vectors(D.text, textconfig=T.textconfig, model=fmodel)\n",
    "\n",
    "finvfile = WeightedInvertedFile(length(fT.model.voc))\n",
    "append_items!(finvfile, VectorDatabase(fT.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d118cb7-f81d-4ad1-80fd-4a5245098ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ],
      "text/plain": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary{TokenLookup} <: Any\n",
      "  lookup::TokenLookup\n",
      "  textconfig::TextConfig\n",
      "  token::Vector{String}\n",
      "  occs::Vector{Int32}\n",
      "  ndocs::Vector{Int32}\n",
      "  token2id::Dict{String, UInt32}\n",
      "  corpuslen::Int64\n"
     ]
    }
   ],
   "source": [
    "display(@htl \"The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)\")\n",
    "\n",
    "dump(typeof(T.model.voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f207f2-ed09-4fec-9da6-2ad625c21801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluaciÃ³n exhaustiva\n",
    "brute = ExhaustiveSearch(; db=T.vectors, dist=NormalizedCosineDistance())\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046760fa-03d2-4bc9-a6cd-418c4f655b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qvectors = VectorDatabase(vectorize_corpus(T.model, Q.text))\n",
    "fQvectors = VectorDatabase(vectorize_corpus(fT.model, Q.text))\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad823b-70c0-447d-bfe0-8a920525ca12",
   "metadata": {},
   "source": [
    "## La siguiente celda se debe correr 2 veces para remover el costo de compilaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde30ad5-8c2d-4622-b0c2-994802b64e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.317168 seconds (1.38 M allocations: 96.354 MiB, 1727.62% compilation time)\n",
      "  4.999678 seconds (268.44 k allocations: 18.960 MiB, 5.08% compilation time)\n",
      "  0.030865 seconds (10.13 k allocations: 1.804 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC.enable(false)\n",
    "k = 31\n",
    "@time Iknns, _ = searchbatch(invfile, Qvectors, k)\n",
    "@time Bknns, _ = searchbatch(brute, Qvectors, k)\n",
    "@time fIknns, _ = searchbatch(finvfile, fQvectors, k)\n",
    "GC.enable(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a30661-03e2-4a19-abf0-9ae801bdeb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd3028d-3907-4bfb-a4ac-7908c91a6556",
   "metadata": {},
   "source": [
    "# El efecto en la calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc566c35-ebb2-4725-a524-a0737319db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(macrof1 = 0.06309231433007588, macrorecall = 0.06881181054086415, accuracy = 0.07)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(macrof1 = 0.06309231433007588, macrorecall = 0.06881181054086415, accuracy = 0.07)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(macrof1 = 0.05999268794791886, macrorecall = 0.06398801060401818, accuracy = 0.0648)\n"
     ]
    }
   ],
   "source": [
    "# La diferencia de costos puede ser importante\n",
    "# por lo que es tambiÃ©n necesario saber el impacto con respecto a la calidad perdida\n",
    "# Recuerde que esta es una evaluaciÃ³n estocÃ¡stica\n",
    "let \n",
    "    @info scores(Q.labels, knn(Bknns, D.labels))\n",
    "    @info scores(Q.labels, knn(Iknns, D.labels))\n",
    "    @info scores(Q.labels, knn(fIknns, D.labels))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f23a7-1e9c-4091-a63c-84695e325598",
   "metadata": {},
   "source": [
    "# Sobre los resultados\n",
    "Lo primero que puede observarse en los resultados es que no son tan buenos como podrÃ­a desearse; recuerde que nuestro objetivo esta en la bÃºsqueda. TambiÃ©n se debe tener en cuenta que esta lejos de una soluciÃ³n aleatoria, ya que son 64 etiquetas. Se puede ver como se multiplica la velocidad varias veces con una calidad muy semejante. En lo posterior, veremos como estos nÃºmeros variarÃ¡n usando diferentes tÃ©cnicas.\n",
    "\n",
    "Finalmente, es necesario remarcar que bÃºsqueda el objetivo es dar a los usuarios informaciÃ³n de Ãºtilidad, y esto suele evaluarse con _gold standards_ generados por humanos. La cantidad de informaciÃ³n serÃ¡ mucho mayor que en tareas de clasificaciÃ³n, y muchas veces, la velocidad es primordial, y si los usuarios encuentran de utilidad los resultados se puede decir que el modelo es efectivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be69f7-5458-4e1c-b0fa-a14ab2600986",
   "metadata": {},
   "source": [
    "# Actividades\n",
    "\n",
    "- Â¿QuÃ© es el recall?\n",
    "- Â¿QuÃ© es macro-recall?\n",
    "- Explique el porque de las mejoras en tiempo. Use anÃ¡lisis de algoritmos para este ejercicio.\n",
    "- Implemente un Ã­ndice invertido que sea capaz de mejorar los tiempos de bÃºsqueda tal y como se muestra en este ejercicio. Para el procesamiento del texto y toquenizado use librerias/paquetes externos.\n",
    "- Reporte mediante un notebook de Jupyter su implementaciÃ³n, use uno de los conjuntos de datos para ejemplificar su uso y medir los desempeÃ±os.\n",
    "\n",
    "# BibliografÃ­a\n",
    "- [SMR2008] SchÃ¼tze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval (Vol. 39, pp. 234-65). Cambridge: Cambridge University Press.\n",
    "- [BYN1999] Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern information retrieval (Vol. 463). New York: ACM press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
